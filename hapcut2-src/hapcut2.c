#include<stdio.h>
#include<stdlib.h>
#include<time.h>
#include<math.h>
#include<string.h>

// data structures and global variables 
#include "common.h" // datastructures for fragments, variants and haplotype blocks
#include "optionparser.c" // global variables and parse command line arguments to change these variables 

// input related
#include "fragmatrix.h" // functions for building SNP-fragment graph 
#include "readinputfiles.h" // read fragment matrix generated by extracthairs
#include "readvcf.h" // read VCF file 
#include "readstats.c"

// optimization related
#include "pointerheap.h"  // heap for max-cut greedy algorithm
#include "find_maxcut.c"   // function compute_good_cut
#include "post_processing.c"  // post-process haplotypes to remove SNVs with low-confidence phasing, split blocks 
#include "hic.h"  // HiC relevant functions

// output related
#include "outvcf.c" // output VCF phased file
#include "output_phasedblocks.c" // output phased haplotypes in original HapCUT format
#include "haplotags.c" // output haplotype assignment for each long read based on final haplotypes


// captures all the relevant data structures together
typedef struct    
{
	struct fragment* Flist; int fragments;
	struct SNPfrags* snpfrag; int snps;
	char* HAP1;
	struct BLOCK* clist; int components;
} DATA;

int read_input_data(char* fragmentfile,char* variantfile,DATA* data)
{
    // READ FRAGMENT MATRIX
    data->fragments = get_num_fragments(fragmentfile); 
    data->Flist = (struct fragment*) malloc(sizeof (struct fragment)* data->fragments);
    int flag = read_fragment_matrix(fragmentfile, data->Flist, data->fragments);
    int new_fragments = 0;
    struct fragment* new_Flist;
    int i=0;

    if (MAX_IS != -1){
        // we are going to filter out some insert sizes, is some memory being lost here?
        new_fragments = 0;
        new_Flist = (struct fragment*) malloc(sizeof (struct fragment)* data->fragments);
        for(i = 0; i < data->fragments; i++){
            if (data->Flist[i].isize < MAX_IS) new_Flist[new_fragments++] = data->Flist[i];
        }
        data->Flist = new_Flist;
        data->fragments = new_fragments;
    }
    if (flag < 0) {
        fprintf_time(stderr, "unable to read fragment matrix file %s \n", fragmentfile);
        return 0;
    }
    data->snps = count_variants_vcf(variantfile);
    if (data->snps < 0) {
        fprintf_time(stderr, "unable to read variant file %s \n", variantfile);
        return 0;
    }
    else // read VCF file
    {
	   data->snpfrag = (struct SNPfrags*) malloc(sizeof (struct SNPfrags)*data->snps);
    	   read_vcffile(variantfile, data->snpfrag, data->snps);
    }
    return 1;	
} 

void init_random_hap(struct SNPfrags* snpfrag,int snps,char* HAP1)
{
    int i=0;
    for (i = 0; i < snps; i++) 
    {
	// this should be checked only after fragments per SNV have been counted
        if (snpfrag[i].frags == 0 || (SNVS_BEFORE_INDELS && (strlen(snpfrag[i].allele0) != 1 || strlen(snpfrag[i].allele1) != 1)) || snpfrag[i].ignore == '1') 
        {
            HAP1[i] = '-';  
        } 
        else if (drand48() < 0.5) HAP1[i] = '0';
        else HAP1[i] = '1';
    }
}

void free_memory(struct SNPfrags* snpfrag,int snps,struct BLOCK* clist,int components)
{
     int i=0;
    for (i = 0; i < snps; i++) free(snpfrag[i].elist);
    for (i = 0; i < snps; i++) free(snpfrag[i].telist);
    int component = 0;
    for (i = 0; i < snps; i++) {
        free(snpfrag[i].flist);
        free(snpfrag[i].alist);
        free(snpfrag[i].jlist);
        free(snpfrag[i].klist);

        if (snpfrag[i].component == i && snpfrag[i].csize > 1) // root node of component
        {
            free(clist[component].slist);
            component++;
        }
    }
    for (i = 0; i < components; i++) free(clist[i].flist);
}

int maxcut_haplotyping(char* fragmentfile, char* variantfile, char* outputfile) {
    // IMP NOTE: all SNPs start from 1 instead of 0 and all offsets are 1+

    int iter = 0, components = 0;
    int i = 0, k = 0;
    int* slist;
    float bestscore = 0, miscalls = 0;
    int hic_iter=0;
    float HIC_LL_SCORE = -80;
    float OLD_HIC_LL_SCORE = -80;
    int converged_count=0, split_count, new_components, component;

    // read input files
    DATA data; 
    if (read_input_data(fragmentfile,variantfile,&data) < 1)  return -1;

    struct fragment* Flist = data.Flist; int fragments = data.fragments;
    struct SNPfrags* snpfrag =data.snpfrag; int snps = data.snps;

    LONG_READS = detect_long_reads(Flist,fragments);
    for (i=0;i<snps;i++)
    {
	// ignore homzygous variants, for such variants, the HAP1[i] value is set to '-' to avoid using them for phasing  
	if (snpfrag[i].genotypes[0] == snpfrag[i].genotypes[2]) snpfrag[i].ignore = '1'; 
	else snpfrag[i].ignore = '0'; 
    }
    update_snpfrags(Flist, fragments, snpfrag, snps,&components);

    // INITIALIZE RANDOM HAPLOTYPES
    data.HAP1 = (char*) malloc(snps + 1);
    char* HAP1 = data.HAP1;
    init_random_hap(snpfrag,snps,HAP1);

    // 10/25/2014, edges are only added between adjacent nodes in each fragment and used for determining connected components...
   // for (i = 0; i < snps; i++) snpfrag[i].elist = (struct edge*) malloc(sizeof (struct edge)*(snpfrag[i].edges+1)); // # of edges calculated in update_snpfrags function 
    if (LONG_READS ==0)  add_edges(Flist,fragments,snpfrag,snps,&components);
    else if (LONG_READS >=1) add_edges_longreads(Flist,fragments,snpfrag,snps,&components);
    for (i = 0; i < snps; i++) snpfrag[i].telist = (struct edge*) malloc(sizeof (struct edge)*(snpfrag[i].edges+1));

    fprintf_time(stderr, "starting Max-Likelihood-Cut based haplotype assembly algorithm\n");
    fprintf_time(stderr, "fragments %d snps %d component(blocks) %d\n", fragments, snps, components);

    // BUILD COMPONENT LIST
    data.clist = (struct BLOCK*) malloc(sizeof (struct BLOCK)*components);
    data.components = components;
    struct BLOCK* clist = data.clist;
    generate_clist_structure(Flist, fragments, snpfrag, snps, components, clist);
    // for each block, we maintain best haplotype solution under MFR criterion
    // compute the component-wise score for 'initHAP' haplotype
    miscalls = 0;
    bestscore = 0;
    for (k = 0; k < components; k++) {
        clist[k].SCORE = 0;
        clist[k].bestSCORE = 0;
        for (i = 0; i < clist[k].frags; i++) {
            update_fragscore(Flist, clist[k].flist[i], HAP1);
            clist[k].SCORE += Flist[clist[k].flist[i]].currscore;
        }
        clist[k].bestSCORE = clist[k].SCORE;
        bestscore += clist[k].bestSCORE;
        miscalls += clist[k].SCORE;
    }
    /////////////  initialization of connected components and data structures for hapcut  ///////////////////////////////////////
    fprintf_time(stderr, "processed fragment file and variant file: fragments %d variants %d\n", fragments, snps);

    HTRANS_MAXBINS = 0;
    if (HIC) init_HiC(Flist,fragments,HTRANS_DATA_INFILE);

    slist = (int*) malloc(sizeof (int)*snps);

    OLD_HIC_LL_SCORE = bestscore;
    for (hic_iter = 0; hic_iter < MAX_HIC_EM_ITER; hic_iter++){ // single iteration except for HiC 
        if (VERBOSE)
            fprintf_time(stdout, "HIC ITER %d\n", hic_iter);
        for (k = 0; k < components; k++){
            clist[k].iters_since_improvement = 0;
        }
        for (i=0; i<snps; i++){
            snpfrag[i].post_hap = 0;
        }
        // RUN THE MAX_CUT ALGORITHM ITERATIVELY TO IMPROVE LIKELIHOOD
        for (iter = 0; iter < MAXITER; iter++) {
            if (VERBOSE)
                fprintf_time(stdout, "PHASING ITER %d\n", iter);
            converged_count = 0;
            for (k = 0; k < components; k++){
                if(VERBOSE && iter == 0)
                    fprintf_time(stdout, "component %d length %d phased %d %d...%d\n", k, clist[k].length, clist[k].phased, clist[k].offset, clist[k].lastvar);
                if (clist[k].SCORE > 0)
                    converged_count += evaluate_cut_component(Flist, snpfrag, clist, k, slist, HAP1);
                else converged_count++;
            }

            if (converged_count == components) {
                //fprintf(stdout, "Haplotype assembly terminated early because no improvement seen in blocks after %d iterations\n", CONVERGE);
                break;
            }
        }

        // H-TRANS ESTIMATION FOR HIC
        if (MAX_HIC_EM_ITER > 1){

            // Possibly break if we're done improving
            HIC_LL_SCORE = 0;
            for (k = 0; k < components; k++){
                HIC_LL_SCORE += clist[k].bestSCORE;
            }
            if (HIC_LL_SCORE >= OLD_HIC_LL_SCORE){
                break;
            }
            OLD_HIC_LL_SCORE = HIC_LL_SCORE;

            likelihood_pruning(snps, Flist, snpfrag, HAP1, 0); // prune for only very high confidence SNPs
            // estimate the h-trans probabilities for the next round
            estimate_htrans_probs(Flist, fragments, HAP1, snpfrag,HTRANS_DATA_OUTFILE);
        }
    }

    // BLOCK SPLITTING
    new_components = components;
    if (SPLIT_BLOCKS){
        split_count = 0;
        for (k=0; k<components; k++){
            // attempt to split block
            split_count += split_block(HAP1, clist, k, Flist, snpfrag, &new_components);
        }
        if (split_count > 0){
            // regenerate clist if necessary
            free(clist);
            clist = (struct BLOCK*) malloc(sizeof (struct BLOCK)*new_components);
            generate_clist_structure(Flist, fragments, snpfrag, snps, new_components, clist);
        }
        components = new_components;
    }else if(ERROR_ANALYSIS_MODE && !HIC){
        for (k=0; k<components; k++){
            // run split_block but don't actually split, just get posterior probabilities
            split_block(HAP1, clist, k, Flist, snpfrag, &new_components);
        }
    }

    // PRUNE SNPS
    if (!SKIP_PRUNE){
        //discrete_pruning(snps, fragments, Flist, snpfrag, HAP1);
	//if (UNPHASED ==1) unphased_optim(snps,Flist,snpfrag,HAP1);
        likelihood_pruning(snps, Flist, snpfrag, HAP1, CALL_HOMOZYGOUS);
    }

    // PRINT OUTPUT FILES
    fprintf_time(stderr, "OUTPUTTING PRUNED HAPLOTYPE ASSEMBLY TO FILE %s\n", outputfile);
    print_hapfile(clist, components, HAP1, Flist, fragments, snpfrag, variantfile, miscalls, outputfile);

    char assignfile[4096];  sprintf(assignfile,"%s.fragments",outputfile);
    if (OUTPUT_HAPLOTAGS ==1) fragment_assignments(Flist,fragments,snpfrag,HAP1,assignfile); // added 03/10/2018 to output read-haplotype assignments

    char outvcffile[4096];  sprintf(outvcffile,"%s.phased.VCF",outputfile);
    if (OUTPUT_VCF ==1) {
    	fprintf_time(stderr, "OUTPUTTING PHASED VCF TO FILE %s\n", outvcffile);
	output_vcf(variantfile,snpfrag,snps,HAP1,Flist,fragments,outvcffile,0);
    }

    free_memory(snpfrag,snps,clist,components); 
    free(Flist);
    free(snpfrag);
    free(clist);
    return 0;
}

int main(int argc, char** argv) {

    // input arguments are fragment file, variant file with variant information and alleles for each variant
    // number of iterations total, when to output the solution, file to output solution .....
    int i = 0;
    char fragfile[10000]; char VCFfile[10000]; char hapfile[10000];
    strcpy(fragfile, "None"); strcpy(VCFfile, "None"); strcpy(hapfile, "None");
    strcpy(HTRANS_DATA_INFILE, "None"); strcpy(HTRANS_DATA_OUTFILE, "None");

    parse_arguments(argc,argv,fragfile,VCFfile,hapfile);
    maxcut_haplotyping(fragfile, VCFfile, hapfile);

    return 0;
}
